
# ðŸ—£ï¸ Voice-Based Speaker Recognition + ðŸ”Š Text-to-Speech System

This project demonstrates how to use **Text-to-Speech (TTS)** and **Voice Recognition** using classical machine learning (SVM). It generates voice samples using `pyttsx3`, extracts features using `librosa`, and builds a speaker classifier using **Support Vector Machines**. It also contains a snippet for an **Arduino-based smart traffic system** using ultrasonic sensors.

---

## ðŸ”§ Features

- âœ… Convert text into speech (.wav files)
- âœ… Use two different TTS voices (male/female)
- âœ… Extract MFCC audio features using `librosa`
- âœ… Train a classifier to identify which speaker is talking
- âœ… Test unknown voice to predict the speaker
- âœ… Bonus: Arduino traffic light controller using ultrasonic sensors

---

## ðŸ“ Project Structure

```
voice-recognition/
â”‚
â”œâ”€â”€ voices/                 # Folder storing generated speech WAV files
â”‚   â”œâ”€â”€ speaker1.wav
â”‚   â”œâ”€â”€ speaker2.wav
â”‚   â””â”€â”€ test_speaker1.wav
â”‚
â”œâ”€â”€ main.py                 # Main script for generating voice, training, and testing
â”œâ”€â”€ README.md               # You're reading it!
```

---

## ðŸš€ Getting Started

### 1. ðŸ”§ Install Requirements

```bash
pip install pyttsx3 librosa soundfile scikit-learn numpy
```

> You also need to have a TTS voice engine (like SAPI5 on Windows).

---

### 2. ðŸ“¦ Generate Voices

In the code:
```python
generate_speech("Hello, this is speaker one...", "voices/speaker1.wav", voice_1)
generate_speech("Hello, this is speaker two...", "voices/speaker2.wav", voice_2)
```

This creates `.wav` files using two different voice IDs.

---

### 3. ðŸŽ™ï¸ Extract Features & Train Classifier

We extract **MFCCs** (Mel-frequency cepstral coefficients) from audio, and train a **Support Vector Machine** to distinguish speakers.

```python
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)
clf = SVC(kernel='linear')
clf.fit(X_train, y_train)
```

---

### 4. ðŸ” Predict Speaker from New Voice

```python
generate_speech("This is a test phrase...", "voices/test_speaker1.wav", voice_1)
test_mfccs = extract_features("voices/test_speaker1.wav")
predictions = clf.predict(test_mfccs)
```

> The model outputs the most likely speaker (Speaker 1 or 2).

---

## ðŸ”Š Speak Any Text in Real-Time

```python
speak("How are you buddy, what's going on?", voice_1)
```

This speaks the given sentence in real time.

---

## ðŸ” Bonus: Arduino Traffic Light Controller (Snippet)

Embedded at the end of the code is a smart traffic control system using ultrasonic sensors to detect vehicles and prioritize traffic lanes.

### ðŸ‘‡ Key Concepts:
- Distance sensors on 4 lanes
- LED signals (Red, Yellow, Green) per lane
- Priority given to the lane where the car arrived first

ðŸ“Ÿ **Microcontroller Used:** Arduino  
ðŸ’¡ **Sensors Used:** Ultrasonic Distance Sensors  
ðŸ’¡ **Outputs:** Red, Yellow, Green LEDs per lane

---

## ðŸ“œ License

This project is open source and free to use under the **MIT License**.

---

## ðŸ¤ Acknowledgements

- [`pyttsx3`](https://pypi.org/project/pyttsx3/)
- [`librosa`](https://librosa.org/)
- [`scikit-learn`](https://scikit-learn.org/)
- [Arduino Docs](https://www.arduino.cc/reference/en/)

---

## ðŸ™Œ Author

Made with â¤ï¸ by **[VeerDhawal]**  
> Feel free to fork, contribute, or suggest improvements!
